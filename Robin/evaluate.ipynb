{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the Prediction servers NSitePred and ATPbind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio.PDB import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 SER\n",
      "133 LYS\n",
      "134 ASP\n",
      "135 ALA\n",
      "136 SER\n",
      "137 GLY\n",
      "138 ASN\n",
      "139 LYS\n",
      "140 VAL\n",
      "141 LYS\n",
      "142 ALA\n"
     ]
    }
   ],
   "source": [
    "h = parse_pdb_header('x1/2x14.pdb')\n",
    "#parse per chain\n",
    "chain_of_interest = \"A\"\n",
    "# go through missing residues and print the sequence number of the residue\n",
    "for residue in h['missing_residues']:\n",
    "    if residue[\"chain\"] in chain_of_interest:\n",
    "        print(residue[\"ssseq\"], residue[\"res_name\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 31\u001b[0m\n\u001b[0;32m     23\u001b[0m three_to_one \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mALA\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCYS\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASP\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGLU\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPHE\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGLY\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHIS\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mILE\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLYS\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLEU\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMET\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASN\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRO\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGLN\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mARG\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSER\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTHR\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVAL\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRP\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTYR\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     28\u001b[0m }\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Loop through all files in the directory\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(pdb_directory):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     33\u001b[0m         filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(pdb_directory, filename)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to parse PDB file and convert to DataFrame\n",
    "def pdb_to_dataframe(pdb_file):\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure('structure', pdb_file)\n",
    "    data = []\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            for residue in chain:\n",
    "                for atom in residue:\n",
    "                    data.append([atom.serial_number, atom.name, residue.resname, chain.id, residue.id[1], \n",
    "                                 atom.coord[0], atom.coord[1], atom.coord[2], atom.occupancy, atom.bfactor, atom.element])\n",
    "    columns = ['Atom_ID', 'Atom_Name', 'Residue_Name', 'Chain_ID', 'Residue_ID', \n",
    "               'X', 'Y', 'Z', 'Occupancy', 'Bfactor', 'Element']\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Directory containing the PDB files\n",
    "pdb_directory = '../Files/pdb'\n",
    "\n",
    "# Dictionary to store dataframes\n",
    "pdb_dataframes = {}\n",
    "\n",
    "# Mapping of three-letter amino acid codes to one-letter codes\n",
    "three_to_one = {\n",
    "    'ALA': 'A', 'CYS': 'C', 'ASP': 'D', 'GLU': 'E', 'PHE': 'F',\n",
    "    'GLY': 'G', 'HIS': 'H', 'ILE': 'I', 'LYS': 'K', 'LEU': 'L',\n",
    "    'MET': 'M', 'ASN': 'N', 'PRO': 'P', 'GLN': 'Q', 'ARG': 'R',\n",
    "    'SER': 'S', 'THR': 'T', 'VAL': 'V', 'TRP': 'W', 'TYR': 'Y'\n",
    "}\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(pdb_directory):\n",
    "    if filename.endswith('.pdb'):\n",
    "        filepath = os.path.join(pdb_directory, filename)\n",
    "        pdb_df = pdb_to_dataframe(filepath)\n",
    "        # Keep only specific columns\n",
    "        pdb_df = pdb_df[['Atom_Name', 'Residue_Name', 'Residue_ID']]\n",
    "        # Filter rows for CA atoms\n",
    "        pdb_df = pdb_df[pdb_df['Atom_Name'] == 'CA']\n",
    "        # Remove duplicate rows\n",
    "        pdb_df = pdb_df.drop_duplicates()\n",
    "        # Map three-letter amino acid codes to one-letter codes\n",
    "        pdb_df['Residue_Name'] = pdb_df['Residue_Name'].map(three_to_one)\n",
    "        # Remove index\n",
    "        pdb_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        pdb_dataframes[filename.split(\"_\")[0]] = pdb_df\n",
    "\n",
    "# Display the keys of the dictionary to show the imported dataframes\n",
    "print(pdb_dataframes.keys())\n",
    "# Display the 3f5m.pdb dataframe as a table to test\n",
    "print(pdb_dataframes['3f5m'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['2j9c', '2x14', '3f5m', '4cta', '6ksh'])\n",
      "  Residue_Name  Residue_ID ATP binding res.   ATP prob.\n",
      "0            M           1                N       0.023\n",
      "1            A           2                N       0.027\n",
      "2            V           3                N       0.027\n",
      "3            E           4                N       0.031\n",
      "4            S           5                N       0.027\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the NSite predictions\n",
    "directory = '../Files/NSite_predictions'\n",
    "\n",
    "# Dictionary to store dataframes\n",
    "ns_predictions = {}\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        # Filter for relevant information\n",
    "        df = df[['AA', 'ATP binding res.', ' ATP prob.']]\n",
    "        df.rename(columns={'AA': 'Residue_Name'}, inplace=True)\n",
    "        # Get the starting Residue_ID from the corresponding PDB dataframe\n",
    "        pdb_key = filename.split(\"_\")[0]\n",
    "        if pdb_key in pdb_dataframes:\n",
    "            start_residue_id = pdb_dataframes[pdb_key]['Residue_ID'].iloc[0]\n",
    "            start_residue_id = start_residue_id < 0 and start_residue_id or 1\n",
    "            df.insert(1, 'Residue_ID', range(start_residue_id, start_residue_id + len(df)))\n",
    "            ns_predictions[pdb_key] = df\n",
    "\n",
    "# Display the keys of the dictionary to show the imported dataframes\n",
    "print(ns_predictions.keys())\n",
    "print(ns_predictions['3f5m'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each dataframe in pdb_dataframes to the directory of this script\n",
    "for filename, dataframe in pdb_dataframes.items():\n",
    "    dataframe.to_csv(filename + \"_pdb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the prediction and PDB dataframes have the same residue name for each residue ID\n",
    "for filename, pdb_df in pdb_dataframes.items():\n",
    "    nsite_df = ns_predictions[filename]    \n",
    "        \n",
    "    # Assuming pdb_df and nsite_df are your dataframes\n",
    "    result = pd.merge(pdb_df, nsite_df, on='Residue_ID', how='left', suffixes=('_pdb', '_nsite'))\n",
    "    \n",
    "    # Display the Residue Id for which the Residue Name is different\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
