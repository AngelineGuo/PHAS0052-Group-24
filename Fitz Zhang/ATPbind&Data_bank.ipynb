{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the position of ATP of predicted result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件：1mb9_chainB.csv, 预测的ATP结合位点数量：8, 位置：[243, 244, 246, 247, 248, 249, 266, 267]\n",
      "文件：2j9c_chainA.csv, 预测的ATP结合位点数量：12, 位置：[9, 37, 38, 39, 41, 60, 88, 89, 90, 91, 92, 105]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# 指定你的文件夹路径\n",
    "folder_path = 'predicted_test'  # 替换成你的文件夹路径\n",
    "\n",
    "# 使用 glob 获取文件夹下所有 CSV 文件的完整路径\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "# 创建一个列表保存每个文件的结果\n",
    "results = []\n",
    "\n",
    "# 遍历每个 CSV 文件\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # 根据 'ATPseq Binding Sites' 列筛选出预测为ATP结合位点的行（这里假设标记 'B' 表示结合位点）\n",
    "    atpseq_binding = df[df['ATPseq Binding Sites'] == 'B']\n",
    "    \n",
    "    # 提取位置编号（假设存储在 'NO' 列中），也可以根据需求提取其它信息\n",
    "    positions = atpseq_binding['NO'].tolist()\n",
    "    \n",
    "    # 保存结果：可以保存文件名、预测的位点位置及个数等信息\n",
    "    results.append({\n",
    "        'filename': os.path.basename(file),\n",
    "        'binding_positions': positions,\n",
    "        'num_binding': len(positions)\n",
    "    })\n",
    "\n",
    "# 输出每个文件的结果，便于比较\n",
    "for res in results:\n",
    "    print(f\"文件：{res['filename']}, 预测的ATP结合位点数量：{res['num_binding']}, 位置：{res['binding_positions']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the position of ATP of experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件：1mb9_chainB.pdb, 预测的ATP结合点位数量：18, 位置：[247, 248, 249, 251, 252, 253, 254, 271, 272, 273, 330, 333, 346, 347, 348, 351, 423, 443]\n",
      "文件：2j9c_chainA.pdb, 预测的ATP结合点位数量：13, 位置：[7, 35, 36, 37, 38, 44, 58, 86, 87, 88, 89, 90, 92]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from Bio.PDB import PDBParser, NeighborSearch\n",
    "from Bio.PDB.Polypeptide import is_aa\n",
    "\n",
    "# 指定存放 PDB 文件的文件夹路径（请替换为你的实际路径）\n",
    "folder_path = 'raw_test'\n",
    "\n",
    "# 获取文件夹下所有 pdb 文件\n",
    "pdb_files = glob.glob(os.path.join(folder_path, '*.pdb'))\n",
    "\n",
    "# 初始化 PDBParser\n",
    "parser = PDBParser(QUIET=True)\n",
    "\n",
    "# 设置距离阈值（单位：Å）\n",
    "threshold = 4.0\n",
    "\n",
    "for pdb_file in pdb_files:\n",
    "    structure = parser.get_structure(os.path.basename(pdb_file), pdb_file)\n",
    "\n",
    "    # 查找所有 ATP 配体的原子（ATP一般以 HETATM 记录出现）\n",
    "    atp_atoms = []\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            for residue in chain:\n",
    "                if residue.get_resname() == \"ATP\":\n",
    "                    for atom in residue:\n",
    "                        atp_atoms.append(atom)\n",
    "\n",
    "    # 如果没有找到 ATP 配体，则认为无结核点位\n",
    "    if not atp_atoms:\n",
    "        print(f\"文件：{os.path.basename(pdb_file)}, 无结核点位（未找到 ATP 配体）。\")\n",
    "        continue\n",
    "\n",
    "    # 收集所有标准氨基酸的原子\n",
    "    protein_atoms = []\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            for residue in chain:\n",
    "                if is_aa(residue, standard=True):\n",
    "                    protein_atoms.extend(list(residue.get_atoms()))\n",
    "\n",
    "    # 构建邻域搜索树\n",
    "    ns = NeighborSearch(protein_atoms)\n",
    "\n",
    "    # 存储 ATP 结合点位对应的残基信息，格式为 (chain_id, residue_id, resname)\n",
    "    binding_residues = set()\n",
    "    for atp_atom in atp_atoms:\n",
    "        close_atoms = ns.search(atp_atom.get_coord(), threshold)\n",
    "        for atom in close_atoms:\n",
    "            residue = atom.get_parent()\n",
    "            if is_aa(residue, standard=True):\n",
    "                chain_id = residue.get_parent().get_id()\n",
    "                res_id = residue.get_id()  # 格式为 (hetfield, 序号, insertion code)\n",
    "                binding_residues.add((chain_id, res_id, residue.get_resname()))\n",
    "\n",
    "    # 提取所有结合点的残基序号（忽略链信息和三字母代码）\n",
    "    positions = sorted([res_id[1] for _, res_id, _ in binding_residues])\n",
    "\n",
    "    filename = os.path.basename(pdb_file)\n",
    "    if binding_residues:\n",
    "        count = len(binding_residues)\n",
    "        print(f\"文件：{filename}, 预测的ATP结合点位数量：{count}, 位置：{positions}\")\n",
    "    else:\n",
    "        print(f\"文件：{filename}, 无结核点位\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract ATP position from PDB file from PDB data bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成文件: ATP_extracted\\121p_chainA.csv\n",
      "生成文件: ATP_extracted\\1d4x_chainA.csv\n",
      "生成文件: ATP_extracted\\1f3f_chainC.csv\n",
      "生成文件: ATP_extracted\\1fit_chainA.csv\n",
      "生成文件: ATP_extracted\\1i58_chainA.csv\n",
      "生成文件: ATP_extracted\\1j09_chainA.csv\n",
      "生成文件: ATP_extracted\\1k90_chainA.csv\n",
      "生成文件: ATP_extracted\\1mb9_chainB.csv\n",
      "生成文件: ATP_extracted\\1rn8_chainA.csv\n",
      "生成文件: ATP_extracted\\1s1d_chainA.csv\n",
      "生成文件: ATP_extracted\\1to6_chainA.csv\n",
      "生成文件: ATP_extracted\\1twf_chainB.csv\n",
      "生成文件: ATP_extracted\\1un9_chainA.csv\n",
      "生成文件: ATP_extracted\\1vl1_chainA.csv\n",
      "生成文件: ATP_extracted\\1wc6_chainB.csv\n",
      "生成文件: ATP_extracted\\1xdn_chainA.csv\n",
      "生成文件: ATP_extracted\\1xdp_chainA.csv\n",
      "生成文件: ATP_extracted\\1yzy_chainA.csv\n",
      "生成文件: ATP_extracted\\1z0s_chainA.csv\n",
      "生成文件: ATP_extracted\\2aqx_chainB.csv\n",
      "生成文件: ATP_extracted\\2bz0_chainA.csv\n",
      "生成文件: ATP_extracted\\2f17_chainA.csv\n",
      "生成文件: ATP_extracted\\2i1o_chainA.csv\n",
      "生成文件: ATP_extracted\\2j9c_chainA.csv\n",
      "生成文件: ATP_extracted\\2jg1_chainC.csv\n",
      "生成文件: ATP_extracted\\2py7_chainX.csv\n",
      "生成文件: ATP_extracted\\2q16_chainB.csv\n",
      "生成文件: ATP_extracted\\2x14_chainA.csv\n",
      "生成文件: ATP_extracted\\2xan_chainA.csv\n",
      "生成文件: ATP_extracted\\3amt_chainA.csv\n",
      "生成文件: ATP_extracted\\3c1m_chainC.csv\n",
      "生成文件: ATP_extracted\\3dnt_chainA.csv\n",
      "生成文件: ATP_extracted\\3erc_chainC.csv\n",
      "生成文件: ATP_extracted\\3f2b_chainA.csv\n",
      "生成文件: ATP_extracted\\3f5m_chainA.csv\n",
      "生成文件: ATP_extracted\\3gqk_chainA.csv\n",
      "生成文件: ATP_extracted\\3hy2_chainY.csv\n",
      "生成文件: ATP_extracted\\3jqm_chainB.csv\n",
      "生成文件: ATP_extracted\\3ruv_chainD.csv\n",
      "生成文件: ATP_extracted\\3tux_chainA.csv\n",
      "生成文件: ATP_extracted\\3v2u_chainC.csv\n",
      "生成文件: ATP_extracted\\3vth_chainA.csv\n",
      "生成文件: ATP_extracted\\3wdl_chainB.csv\n",
      "生成文件: ATP_extracted\\3wgu_chainC.csv\n",
      "生成文件: ATP_extracted\\3zcb_chainA.csv\n",
      "生成文件: ATP_extracted\\4amf_chainA.csv\n",
      "生成文件: ATP_extracted\\4crj_chainA.csv\n",
      "生成文件: ATP_extracted\\4cta_chainA.csv\n",
      "生成文件: ATP_extracted\\4edk_chainA.csv\n",
      "生成文件: ATP_extracted\\4ff3_chainA.csv\n",
      "生成文件: ATP_extracted\\4lac_chainC.csv\n",
      "生成文件: ATP_extracted\\4ru9_chainA.csv\n",
      "生成文件: ATP_extracted\\4uxx_chainC.csv\n",
      "生成文件: ATP_extracted\\4yvz_chainA.csv\n",
      "生成文件: ATP_extracted\\5bsm_chainA.csv\n",
      "生成文件: ATP_extracted\\5dd7_chainA.csv\n",
      "生成文件: ATP_extracted\\5dgh_chainA.csv\n",
      "生成文件: ATP_extracted\\5guf_chainA.csv\n",
      "生成文件: ATP_extracted\\5trd_chainA.csv\n",
      "生成文件: ATP_extracted\\5w51_chainE.csv\n",
      "生成文件: ATP_extracted\\6a8p_chainB.csv\n",
      "生成文件: ATP_extracted\\6aaz_chainA.csv\n",
      "生成文件: ATP_extracted\\6b5k_chainA.csv\n",
      "生成文件: ATP_extracted\\6c02_chainA.csv\n",
      "生成文件: ATP_extracted\\6cau_chainA.csv\n",
      "生成文件: ATP_extracted\\6ci7_chainC.csv\n",
      "生成文件: ATP_extracted\\6d5k_chainC.csv\n",
      "生成文件: ATP_extracted\\6fl4_chainA.csv\n",
      "生成文件: ATP_extracted\\6h77_chainA.csv\n",
      "生成文件: ATP_extracted\\6ig2_chainD.csv\n",
      "生成文件: ATP_extracted\\6ksh_chainD.csv\n",
      "生成文件: ATP_extracted\\6p1p_chainA.csv\n",
      "生成文件: ATP_extracted\\6r5d_chainA.csv\n",
      "生成文件: ATP_extracted\\6sqz_chainD.csv\n",
      "生成文件: ATP_extracted\\6t0v_chainB.csv\n",
      "生成文件: ATP_extracted\\6txe_chainA.csv\n",
      "生成文件: ATP_extracted\\6vd0_chainA.csv\n",
      "生成文件: ATP_extracted\\7alr_chainA.csv\n",
      "生成文件: ATP_extracted\\7cqq_chainA.csv\n",
      "生成文件: ATP_extracted\\7d8i_chainA.csv\n",
      "生成文件: ATP_extracted\\7edz_chainC.csv\n",
      "生成文件: ATP_extracted\\7fgg_chainA.csv\n",
      "生成文件: ATP_extracted\\7nsd_chainA.csv\n",
      "生成文件: ATP_extracted\\7tgk_chainD.csv\n",
      "生成文件: ATP_extracted\\7uld_chainA.csv\n",
      "生成文件: ATP_extracted\\7v0f_chainA.csv\n",
      "生成文件: ATP_extracted\\7y7p_chainA.csv\n",
      "生成文件: ATP_extracted\\8dbj_chainA.csv\n",
      "生成文件: ATP_extracted\\8dcd_chainA.csv\n",
      "批量处理完成！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "from Bio.PDB import PDBParser, NeighborSearch\n",
    "from Bio.PDB.Polypeptide import is_aa, three_to_one\n",
    "\n",
    "# 指定存放 PDB 文件的文件夹路径（请替换为你的实际路径）\n",
    "input_folder = 'extracted_chains'  # 输入PDB文件夹路径\n",
    "# 指定存放生成的 CSV 文件的文件夹路径\n",
    "output_folder = 'ATP_extracted'  # 输出CSV文件夹路径\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 获取输入文件夹下所有 pdb 文件\n",
    "pdb_files = glob.glob(os.path.join(input_folder, '*.pdb'))\n",
    "\n",
    "# 初始化 PDBParser\n",
    "parser = PDBParser(QUIET=True)\n",
    "\n",
    "# 设置距离阈值（单位：Å）\n",
    "threshold = 4.0\n",
    "\n",
    "for pdb_file in pdb_files:\n",
    "    # 解析 PDB 文件\n",
    "    structure = parser.get_structure(os.path.basename(pdb_file), pdb_file)\n",
    "    # 使用文件名（去除扩展名）作为 Prot.ID\n",
    "    prot_id_base = os.path.splitext(os.path.basename(pdb_file))[0]\n",
    "\n",
    "    # 1. 提取所有 ATP 配体的原子（ATP通常以 HETATM 记录出现）\n",
    "    atp_atoms = []\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            for residue in chain:\n",
    "                if residue.get_resname() == \"ATP\":\n",
    "                    atp_atoms.extend(list(residue.get_atoms()))\n",
    "    \n",
    "    # 2. 利用 ATP 配体的原子，利用邻域搜索找出 ATP 结合点位\n",
    "    binding_residues = set()  # 保存格式：(chain_id, residue_id, 三字母残基代码)\n",
    "    if atp_atoms:\n",
    "        # 收集所有标准氨基酸的原子\n",
    "        protein_atoms = []\n",
    "        for model in structure:\n",
    "            for chain in model:\n",
    "                for residue in chain:\n",
    "                    if is_aa(residue, standard=True):\n",
    "                        protein_atoms.extend(list(residue.get_atoms()))\n",
    "        ns = NeighborSearch(protein_atoms)\n",
    "        for atp_atom in atp_atoms:\n",
    "            close_atoms = ns.search(atp_atom.get_coord(), threshold)\n",
    "            for atom in close_atoms:\n",
    "                residue = atom.get_parent()\n",
    "                if is_aa(residue, standard=True):\n",
    "                    chain_id = residue.get_parent().get_id()\n",
    "                    res_id = residue.get_id()  # 格式为 (hetfield, 序号, insertion code)\n",
    "                    binding_residues.add((chain_id, res_id, residue.get_resname()))\n",
    "    \n",
    "    # 3. 遍历所有标准氨基酸残基，生成 CSV 的每一行\n",
    "    rows = []\n",
    "    header = ['Prot.ID', 'NO', 'Residue', 'ATP Binding Site']\n",
    "    rows.append(header)\n",
    "    \n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            chain_id = chain.get_id()\n",
    "            for residue in chain:\n",
    "                if not is_aa(residue, standard=True):\n",
    "                    continue\n",
    "                res_id = residue.get_id()  # (het, seq_number, insertion code)\n",
    "                # 转换三字母代码为一字母代码\n",
    "                try:\n",
    "                    res_one = three_to_one(residue.get_resname())\n",
    "                except Exception as e:\n",
    "                    res_one = residue.get_resname()\n",
    "                # 判断是否为 ATP 结合点位\n",
    "                if (chain_id, res_id, residue.get_resname()) in binding_residues:\n",
    "                    binding_flag = \"B\"\n",
    "                else:\n",
    "                    binding_flag = \"N\"\n",
    "                row = [prot_id_base, res_id[1], res_one, binding_flag]\n",
    "                rows.append(row)\n",
    "    \n",
    "    # 4. 写入 CSV 文件，文件名与 PDB 文件名对应\n",
    "    output_file = os.path.join(output_folder, prot_id_base + '.csv')\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(rows)\n",
    "    \n",
    "    print(f\"生成文件: {output_file}\")\n",
    "\n",
    "print(\"批量处理完成！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare residue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件 121p_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 1d4x_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 1f3f_chainC.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 1fit_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 1i58_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 1j09_chainA.csv: 长度不匹配 -> 真值长度: 469, 预测长度: 468\n",
      "文件 1j09_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 1k90_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 1mb9_chainB.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 1rn8_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 1s1d_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 1to6_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 1twf_chainB.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 1un9_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 1vl1_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 1wc6_chainB.csv: 长度不匹配 -> 真值长度: 193, 预测长度: 192\n",
      "文件 1wc6_chainB.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 1xdn_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 1xdp_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 1yzy_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 1z0s_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 2aqx_chainB.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 2bz0_chainA.csv: 长度不匹配 -> 真值长度: 169, 预测长度: 168\n",
      "文件 2bz0_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 2f17_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 2i1o_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 2j9c_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 2jg1_chainC.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 2py7_chainX.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 2q16_chainB.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 2x14_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 2xan_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 3amt_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 3c1m_chainC.csv: 长度不匹配 -> 真值长度: 469, 预测长度: 468\n",
      "文件 3c1m_chainC.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 3dnt_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 3erc_chainC.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 3f2b_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 3f5m_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 3gqk_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 3hy2_chainY.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 3jqm_chainB.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 3ruv_chainD.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 3tux_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 3v2u_chainC.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 3vth_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 3wdl_chainB.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 3wgu_chainC.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 3zcb_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 4amf_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 4crj_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 4cta_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 4edk_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 4ff3_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 4lac_chainC.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 4ru9_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 4uxx_chainC.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 4yvz_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 5bsm_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 5dd7_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 5dgh_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 5guf_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 5trd_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 5w51_chainE.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 6a8p_chainB.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 6aaz_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 6b5k_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 6c02_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 6cau_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 6ci7_chainC.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 6d5k_chainC.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 6fl4_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 6h77_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 6ig2_chainD.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 6ksh_chainD.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 6p1p_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 6r5d_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 6sqz_chainD.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 6t0v_chainB.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 6txe_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 6vd0_chainA.csv: 长度不匹配 -> 真值长度: 393, 预测长度: 392\n",
      "文件 6vd0_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 7alr_chainA.csv: 长度不匹配 -> 真值长度: 426, 预测长度: 425\n",
      "文件 7alr_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 7cqq_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 7d8i_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 7edz_chainC.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 7fgg_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 7nsd_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 7tgk_chainD.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 7uld_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 7v0f_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 7y7p_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 8dbj_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n",
      "文件 8dcd_chainA.csv: 最短范围内Residue匹配，但整体长度不一致。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# 真值CSV文件存放文件夹（例如提取后的文件）\n",
    "gt_folder = 'ATP_extracted'\n",
    "# 预测结果CSV文件存放文件夹\n",
    "pred_folder = 'predicted_result'\n",
    "\n",
    "# 获取真值文件夹下所有 CSV 文件\n",
    "gt_files = glob.glob(os.path.join(gt_folder, '*.csv'))\n",
    "\n",
    "# 遍历每个真值文件\n",
    "for gt_file in gt_files:\n",
    "    base_name = os.path.basename(gt_file)\n",
    "    pred_file = os.path.join(pred_folder, base_name)\n",
    "    \n",
    "    if not os.path.exists(pred_file):\n",
    "        print(f\"预测结果文件不存在: {pred_file}\")\n",
    "        continue\n",
    "\n",
    "    # 读取文件\n",
    "    gt_df = pd.read_csv(gt_file)\n",
    "    pred_df = pd.read_csv(pred_file)\n",
    "    \n",
    "    # 获取Residue列，转换为列表\n",
    "    gt_residues = list(gt_df['Residue'])\n",
    "    pred_residues = list(pred_df['Residue'])\n",
    "    \n",
    "    # 比较长度\n",
    "    if len(gt_residues) != len(pred_residues):\n",
    "        print(f\"文件 {base_name}: 长度不匹配 -> 真值长度: {len(gt_residues)}, 预测长度: {len(pred_residues)}\")\n",
    "    \n",
    "    # 检查是否完全匹配（仅对最短长度范围内比对）\n",
    "    min_len = min(len(gt_residues), len(pred_residues))\n",
    "    mismatches = []\n",
    "    for i in range(min_len):\n",
    "        if gt_residues[i] != pred_residues[i]:\n",
    "            mismatches.append((i, gt_residues[i], pred_residues[i]))\n",
    "    \n",
    "    if mismatches:\n",
    "        print(f\"文件 {base_name}: Residue不匹配:\")\n",
    "        for idx, gt_res, pred_res in mismatches:\n",
    "            print(f\"  索引 {idx}: 真值 = {gt_res}, 预测 = {pred_res}\")\n",
    "    else:\n",
    "        #if len(gt_residues) == len(pred_residues):\n",
    "            #print(f\"文件 {base_name}: Residue完全匹配。\")\n",
    "        #else:\n",
    "            # 即使在最小长度内都匹配，但长度不同也说明存在缺失\n",
    "        print(f\"文件 {base_name}: 最短范围内Residue匹配，但整体长度不一致。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare and calculate TP..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件处理完毕，结果已保存到 evaluation_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import math\n",
    "from Bio import pairwise2\n",
    "\n",
    "def align_labels(gt_residues, pred_residues, gt_binding, pred_binding):\n",
    "    \"\"\"\n",
    "    对gt和pred的Residue序列进行全局比对，\n",
    "    返回对齐后（两边均非gap）的真值结合标签和预测结合标签列表。\n",
    "    \"\"\"\n",
    "    gt_seq = ''.join(gt_residues)\n",
    "    pred_seq = ''.join(pred_residues)\n",
    "    \n",
    "    # 使用简单的全局比对（匹配得1分，不匹配得0分）\n",
    "    alignments = pairwise2.align.globalxx(gt_seq, pred_seq)\n",
    "    best = alignments[0]\n",
    "    gt_aligned, pred_aligned = best.seqA, best.seqB\n",
    "\n",
    "    aligned_gt_binding = []\n",
    "    aligned_pred_binding = []\n",
    "    i, j = 0, 0  # 指向原始序列的指针\n",
    "    for a, b in zip(gt_aligned, pred_aligned):\n",
    "        if a != '-' and b != '-':\n",
    "            # 两边都有字符，则保存对应的结合标签\n",
    "            aligned_gt_binding.append(gt_binding[i])\n",
    "            aligned_pred_binding.append(pred_binding[j])\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif a == '-' and b != '-':\n",
    "            j += 1  # gt比对中出现缺失\n",
    "        elif a != '-' and b == '-':\n",
    "            i += 1  # pred比对中出现缺失\n",
    "        else:\n",
    "            # 同时为gap（很少见）\n",
    "            pass\n",
    "    return aligned_gt_binding, aligned_pred_binding\n",
    "\n",
    "# 真值文件夹和预测结果文件夹（请修改为实际路径）\n",
    "gt_folder = 'ATP_extracted'       # 存放提取后的真值CSV文件\n",
    "pred_folder = 'predicted_result'          # 存放预测结果CSV文件\n",
    "\n",
    "# 获取真值文件夹下所有CSV文件（假设每个蛋白对应一个CSV文件，且文件名一致）\n",
    "gt_files = glob.glob(os.path.join(gt_folder, '*.csv'))\n",
    "\n",
    "results = []\n",
    "\n",
    "for gt_file in gt_files:\n",
    "    base_name = os.path.basename(gt_file)\n",
    "    pred_file = os.path.join(pred_folder, base_name)\n",
    "    \n",
    "    if not os.path.exists(pred_file):\n",
    "        print(f\"预测结果文件不存在: {pred_file}\")\n",
    "        continue\n",
    "\n",
    "    # 读取真值和预测文件\n",
    "    gt_df = pd.read_csv(gt_file)\n",
    "    pred_df = pd.read_csv(pred_file)\n",
    "    \n",
    "    # 提取Residue序列（假设Residue列中的字符为一字母代码）\n",
    "    gt_residues = list(gt_df['Residue'])\n",
    "    pred_residues = list(pred_df['Residue'])\n",
    "    \n",
    "    # 提取真值的结合标签（假设列名为 \"ATP Binding Site\"，'B' 表示正，'N' 表示负）\n",
    "    gt_binding = list(gt_df['ATP Binding Site'])\n",
    "    \n",
    "    # 对于两种预测方法分别计算指标\n",
    "    for method, col in [('ATPseq', 'ATPseq Binding Sites'), ('ATPbind', 'ATPbind Binding Sites')]:\n",
    "        pred_binding = list(pred_df[col])\n",
    "        \n",
    "        # 如果Residue序列不匹配，则使用序列对齐\n",
    "        if gt_residues != pred_residues:\n",
    "            aligned_gt_binding, aligned_pred_binding = align_labels(gt_residues, pred_residues, gt_binding, pred_binding)\n",
    "        else:\n",
    "            aligned_gt_binding = gt_binding\n",
    "            aligned_pred_binding = pred_binding\n",
    "        \n",
    "        # 计算TP, FN, TN, FP（仅在对齐后的位置上计算）\n",
    "        tp = sum(1 for gt, pred in zip(aligned_gt_binding, aligned_pred_binding) if gt == 'B' and pred == 'B')\n",
    "        fn = sum(1 for gt, pred in zip(aligned_gt_binding, aligned_pred_binding) if gt == 'B' and pred == 'N')\n",
    "        tn = sum(1 for gt, pred in zip(aligned_gt_binding, aligned_pred_binding) if gt == 'N' and pred == 'N')\n",
    "        fp = sum(1 for gt, pred in zip(aligned_gt_binding, aligned_pred_binding) if gt == 'N' and pred == 'B')\n",
    "        \n",
    "        sen = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "        spe = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "        acc = (tp + tn) / (tp + fn + tn + fp) if (tp + fn + tn + fp) != 0 else 0\n",
    "        pre = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "        denominator = math.sqrt((tp + fn) * (tp + fp) * (tn + fn) * (tn + fp))\n",
    "        mcc = (tp * tn - fn * fp) / denominator if denominator != 0 else 0\n",
    "        \n",
    "        # 获取Prot.ID，假设真值文件中\"Prot.ID\"列的值都相同，取第一个\n",
    "        prot_id = gt_df['Prot.ID'].iloc[0] if not gt_df.empty else base_name\n",
    "        \n",
    "        results.append({\n",
    "            'Prot.ID': prot_id,\n",
    "            'Method': method,\n",
    "            'TP': tp,\n",
    "            'FN': fn,\n",
    "            'TN': tn,\n",
    "            'FP': fp,\n",
    "            'Sen': sen,\n",
    "            'Spe': spe,\n",
    "            'Acc': acc,\n",
    "            'Pre': pre,\n",
    "            'MCC': mcc\n",
    "        })\n",
    "\n",
    "# 将所有蛋白的评估结果保存到一个CSV文件中\n",
    "results_df = pd.DataFrame(results)\n",
    "output_file = 'evaluation_results.csv'\n",
    "results_df.to_csv(output_file, index=False)\n",
    "print(f\"所有文件处理完毕，结果已保存到 {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
